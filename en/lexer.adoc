= Lexer
:imagesdir: ../images
:toc:
:toclevels: 3
:numbered:

== Concept 


== Loading values

=== `load`

=== `transcode`

*Syntax*

----
transcode <input>

<input> : series to load (binary! string!).

Returns : a single value or a block of values.
----

*Description*

Converts an UTF-8 encoded input binary series into a Red value according to Red syntactic rules. Non-conformity with such rules will result in throwing an error. When a string series is provided, it will be internally first converted to a UTF-8 binary series before processing.

== Scanning values

=== `scan`

*Syntax*

----
scan <input>
scan/fast <input>

<input> : series to scan (binary! string!).

Returns : recognized type (datatype!).
----

*Description*

Scans a string or binary buffer according to Red syntactic rules and stops after the first value is recognized and returns its datatype. No value is loaded, so no extra memory is allocated. If the scanned input is invalid, the `error!` type is returned, no exception occurs.

The `/fast` refinement trades speed for accuracy. The scanning will return the most likely type (not doing any deep validation) using only the very fast internal prescanning engine. Very little error checking is done in such case. The guessed types are shown in the following table:

[cols="1,1", options="header"]
|===
|Guessed type | Real type
|block!	 | block!
|paren!	 | paren!
|string!  | string!
|map!	 | map!
|path!	 | path! +
lit-path! +
get-path! +
set-path!
|integer! | integer! +
float!
|word!	 | word! +
lit-word! +
get-word! + 
set-word!
|refinement! | refinement! +
word! +
lit-word! +
get-word! +
set-word!
|char!	 | char!
|issue!	 | issue!
|file!	 | file!
|binary! | binary!
|percent! | percent!
|float!	 | float!
|tuple!	 | tuple!
|date!	 | date!
|pair!	 | pair!
|time!	 | time!
|money!	 | money!
|tag!	 | tag!
|url!	 | url!
|email!	 | email!
|===

Note: 

* When a string series is provided, it will be internally first converted to a UTF-8 binary series before processing.

* Scanning is much faster than loading and does not allocate any extra memory.

* Scanning is slower than prescanning, as it requires extra code to do deep validation.

== Processing values using iteration

=== `load/next`

=== `transcode/next`

=== `scan/next`

== Instrumenting the lexer

=== The lexer processing pipeline

The tokenization process is split in stages, triggering events where a user-provided callback function can be invoked. The different stages are:

----
                     /-> CLOSE series
                    /-> OPEN series
                   /
PRESCAN token -> SCAN token -> LOAD value
                   \             \
                    \-> ERROR     \-> ERROR
----

=== `transcode/trace`

*Syntax*

----
transcode/trace <input> <callback>

<input>    : series to load (binary! string!).
<callback> : a callback function to process lexer events (function!).

Returns    : a single value or a block of values.
----

*Description*

Note: the body block can start with an optional filtering block, for indicating which events will be triggered. This allows to reduce the number of callback calls resulting in much better processing performance.

Callback function specification block:

----
func [
    event [word!]                    ;-- current lexer state (see table below).
    input [string! binary!]          ;-- reference to the input series at current loading position (can be changed).
    type  [datatype! word! none!]    ;-- word or datatype describing the type of token or value currently processed.
    line  [integer!]                 ;-- current input line number.
    token                            ;-- current token as an input slice (pair!) or a loaded value.
    return: [logic!]
]
----

The meaning of some arguments and return value _depends_ on the event. The following table documents the possible combinations and effects:

[cols="1,1,1,1,2", options="header"]
|===
|Event | Type | Token | Return Value | Description
|`prescan`| word! datatype!| pair!| `true`: scan + 
`false`: drop| When a Red token has been recognized.
|`scan`| word! datatype!| pair!| `true`: load + 
`false`: drop| When a Red token type has been accurately recognized.
|`load`| datatype!| <value>| `true`: store +
`false`: drop| When a Red token has been converted to a Red value.
|`open`| datatype!| pair!| `true`: open +
`false`: drop| When a new block!, paren!, path!, map! or multiline string! is opened.
|`close`| datatype!| pair!| `true`: close + 
`false`: drop| When a new block!, paren!, path!, map! or multiline string! is closed.
|`error`| datatype!| pair!| `true`: throw +
`false`: ignore| When a syntax error occurs.
|===

Possible values for `type` field (word!) in `scan` event:
----
eof comment hex error! block! paren! string! map! path! word! refinement!
issue! file! binary! char! percent! integer! float! tuple! date! pair! time!
money! tag! url! email! lit-word! get-word! set-word!
----

Possible values for `type` field (datatype!) in `open` event:
----
block! paren! string!(1) map! path! lit-path! get-path!
----

Possible values for `type` field (datatype!) in `close` event:
----
block! paren! string!(1) map! path! lit-path! get-path! set-path!
----

(1): only for strings delimited by brackets.

Notes:

* If `false` is returned on a `prescan` event, the corresponding `scan` and `load` events will be skipped.

* If `false` is returned on a `scan` event, the corresponding `load` event will be skipped.

* If an `open` event is dropped, also drop the corresponding `close` event.


== Values Literal Syntax

=== Raw Strings

Strings in Red have special rules for some characters, like using `^` character as escaping mechanism or bracketed strings having to balance nested curly brackets. Raw strings format provides a way to input literal strings without any special treatment of its content.

*Syntax*

----
%{...}%
%%{...}%%
%%%{...}%%%
...
----

Any number of `%` character can be used in order to make the ending sequence not collide with string's content. The leading count of `%` must match the trailing count, otherwise a syntax error will occur on loading.

`^` is processed as a regular character. Curly braces can be used without any escaping or balancing constraint.